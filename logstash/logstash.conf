# Configuração do Logstash para sincronizar livros do backend para Elasticsearch
# Estratégia: Carga Incremental baseada em updatedAt

input {
  # Heartbeat para criar evento trigger a cada 5 minutos
  heartbeat {
    interval => 300  # 300 segundos = 5 minutos
    message => "poll"
  }
}

filter {
  # Faz requisição HTTP com cálculo dinâmico de data
  ruby {
    code => '
      require "net/http"
      require "json"
      require "uri"
      require "time"
      
      # Calcula 6 minutos atrás em UTC (overlap de 1 minuto de segurança)
      six_minutes_ago = (Time.now.utc - (6 * 60)).strftime("%Y-%m-%dT%H:%M:%S.000Z")
      
      # URL encode do parâmetro de data
      encoded_date = URI.encode_www_form_component(six_minutes_ago)
      
      # Monta a URL completa
      url_string = "http://host.docker.internal:3000/livros?updatedAfter=#{encoded_date}"
      
      begin
        uri = URI.parse(url_string)
        http = Net::HTTP.new(uri.host, uri.port)
        http.read_timeout = 60
        
        request = Net::HTTP::Get.new(uri.request_uri)
        response = http.request(request)
        
        if response.code == "200"
          livros = JSON.parse(response.body)
          
          if livros.is_a?(Array)
            # Armazena os livros nos metadata para processar depois
            event.set("[@metadata][livros]", livros)
            event.set("[@metadata][sync_count]", livros.length)
            event.set("[@metadata][sync_timestamp]", six_minutes_ago)
          else
            event.cancel
          end
        else
          event.tag("_http_request_failure")
          event.cancel
        end
      rescue => e
        event.set("[@metadata][error]", e.message)
        event.tag("_ruby_exception")
        event.cancel
      end
    '
  }
  
  # Se encontrou livros, divide em eventos individuais
  if [@metadata][livros] {
    split {
      field => "[@metadata][livros]"
    }
    
    # Move dados do livro para o nível raiz do evento
    ruby {
      code => '
        livro = event.get("[@metadata][livros]")
        if livro.is_a?(Hash)
          livro.each do |key, value|
            event.set(key, value)
          end
        end
      '
    }
  }
  
  # Remove campos desnecessários
  mutate {
    remove_field => ["message", "@version", "host", "sequence", "type", "tags"]
  }
}

output {
  # Envia para o Elasticsearch
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "books"
    document_id => "%{id}"
    # Upsert: cria ou atualiza o documento
    action => "index"
  }
  
  # Exibe no log para debug (opcional)
  stdout {
    codec => rubydebug
  }
}
